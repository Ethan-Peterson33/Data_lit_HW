{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  '''\n",
    "  Returns the sigmoid of z.\n",
    "  Given the logit (AKA the log of the odds), then the sigmoid inverses the log and returns the original value of the odds.\n",
    "  '''\n",
    "  return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def predict(features, weights):\n",
    "\n",
    "    return sigmoid( np.dot(features, weights) )\n",
    "\n",
    "def cost_function_for_all_training_samples(features, labels, weights):\n",
    "    m = features.shape[0]  # m = number of samples\n",
    "    predictions = predict(features, weights)\n",
    "    return -(1/m) * np.sum( labels*np.log(predictions) + (1-labels)*np.log(1-predictions) )\n",
    "\n",
    "def decision_boundary(probability, threshold=0.5):\n",
    "      return 1 if probability >= threshold else 0\n",
    "\n",
    "def calculate_gradient(features, labels, weights):\n",
    "    predictions = predict(features, weights)\n",
    "    matrixOfAggregateSlopeOfCostFunction = np.dot(features.T, predictions - labels)\n",
    "    return matrixOfAggregateSlopeOfCostFunction\n",
    "  \n",
    "\n",
    "def update_weights(features, labels, weights, lr):\n",
    "\n",
    "    matrixOfAggregateSlopeOfCostFunction = calculate_gradient(features, labels, weights)\n",
    "\n",
    "    m = len(features)\n",
    "    averageCostDerivativeForEachFeature = matrixOfAggregateSlopeOfCostFunction / m\n",
    "\n",
    "    gradient = averageCostDerivativeForEachFeature * lr\n",
    "\n",
    "    return weights - gradient\n",
    "\n",
    "\n",
    "def fit(features, labels, weights, lr, iterations):\n",
    "\n",
    "    for i in range(iterations):\n",
    "        weights = update_weights(features, labels, weights, lr)\n",
    "\n",
    "        # Log Progress\n",
    "        if i % 100 == 0:\n",
    "            cost = cost_function_for_all_training_samples(features, labels, weights)\n",
    "            print(\"iteration:\", str(i), \"cost:\", str(cost))\n",
    "\n",
    "    return weights\n",
    "  \n",
    "def _classify(predictions):\n",
    "    decide = np.vectorize(decision_boundary)\n",
    "    return decide(predictions).flatten()\n",
    "\n",
    "def scale(X, norm_params):\n",
    "    x_min = norm_params[0]\n",
    "    x_max = norm_params[1]\n",
    "    nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "    denom = X.max(axis=0) - X.min(axis=0)\n",
    "    denom[denom==0] = 1\n",
    "    return x_min + nom/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_file(data_file, iters):\n",
    "    columns = ['age', 'workclass','fnlwgt','education','education_num','marital_status','occupation','relationship','race','gender','capital_gain','capital_loss','hours_per_week','native_country','income_bracket']\n",
    "    train = pd.read_csv(data_file, names=columns)\n",
    "    test = pd.read_csv('adult-test.csv', names=columns, skiprows=1)\n",
    "    test['income_bracket'] = test['income_bracket'].apply(lambda x: 0 if x==' >50K' else 0)\n",
    "    train['income_bracket'] = train['income_bracket'].apply(lambda x: 1 if x==' >50K' else 0)\n",
    "    train_y = train['income_bracket']\n",
    "    train['training_set'] = True\n",
    "    test['training_set'] = False\n",
    "    all_data = pd.concat([train,test])\n",
    "    \n",
    "    all_data = all_data.drop(['income_bracket'], axis=1)\n",
    "    all_data = pd.get_dummies(all_data)\n",
    "    train_x = all_data[all_data['training_set']==True]\n",
    "    train_x = train_x.drop('training_set', axis=1)\n",
    "    normalization_params = [0,1]\n",
    "    train_x = scale(train_x, normalization_params)\n",
    "    lr = 0.1\n",
    "    initial_weights = [0] * train_x.shape[1]\n",
    "    iterations = iters\n",
    "    weights = fit(train_x, train_y, initial_weights, lr, iterations)\n",
    "    return weights, normalization_params\n",
    "\n",
    "\n",
    "\n",
    "def classify(data_file, weights, normalization_params):\n",
    "    columns = ['age', 'workclass','fnlwgt','education','education_num','marital_status','occupation','relationship','race','gender','capital_gain','capital_loss','hours_per_week','native_country','income_bracket']\n",
    "    test = pd.read_csv(data_file, names=columns, skiprows=1)\n",
    "    train = pd.read_csv('adult-training.csv', names=columns)\n",
    "    test['income_bracket'] = test['income_bracket'].apply(lambda x: 0 if x==' >50K' else 0)\n",
    "    train['income_bracket'] = train['income_bracket'].apply(lambda x: 1 if x==' >50K' else 0)\n",
    "    test_y = test['income_bracket']\n",
    "    train['training_set'] = True\n",
    "    test['training_set'] = False\n",
    "    all_data = pd.concat([train,test])\n",
    "    all_data = all_data.drop(['income_bracket'], axis=1)\n",
    "    all_data = pd.get_dummies(all_data)\n",
    "    all_data = pd.get_dummies(all_data)\n",
    "    test_x = all_data[all_data['training_set']==False]\n",
    "    test_x = test_x.drop('training_set', axis=1)\n",
    "    test_x = scale(test_x, normalization_params)\n",
    "    y_test_probabilities = predict(test_x, weights).flatten()\n",
    "    labels = _classify(y_test_probabilities)\n",
    "    \n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 cost: 0.6673527327501676\n",
      "iteration: 100 cost: 0.4405495171880037\n",
      "iteration: 200 cost: 0.41404065290826714\n",
      "iteration: 300 cost: 0.4015694066704977\n",
      "iteration: 400 cost: 0.3937806593650562\n",
      "iteration: 500 cost: 0.3882647907144724\n",
      "iteration: 600 cost: 0.38405401830484465\n",
      "iteration: 700 cost: 0.38067443839377296\n",
      "iteration: 800 cost: 0.3778658790412143\n",
      "iteration: 900 cost: 0.37547278440910753\n"
     ]
    }
   ],
   "source": [
    "weights, normalization_params = train_with_file(\"adult-training.csv\",1000)\n",
    "\n",
    "labels = classify('adult-test.csv',weights, normalization_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
